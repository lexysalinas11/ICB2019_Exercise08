# Note that this uses scale parameterization for inverse gamma
draw_mean = function(mu_0, sigma.sq_0, varsigma.sq, y){
mu_1 =((mu_0 / sigma.sq_0 + sum(y)/varsigma.sq)) / (1/sigma.sq_0 + length(y) / varsigma.sq)
sigma.sq_1 = 1/(1 / sigma.sq_0 + length(y) / varsigma.sq)
z = rnorm(1, mu_1, sqrt(sigma.sq_1))
param = list(z = z, mu_1 = mu_1, sigma.sq_1 = sigma.sq_1)
return(param)
}
```
5. We have also provided a function called draw_var that makes draws from the marginal posterior distribution for ς2 using a inverse gamma-normal conjugate relationship where the mean is assumed to be known. Study this function relative to the MCMCmath.pdf handout.
```{r}
# normal likelihood with gamma prior conjugate relationship for variance, assuming mean is known
# alpha_0 is parameter of prior for variance
# beta_0 is parameter of prior for variance
# Note that this uses scale parameterization for inverse gamma
draw_var = function(alpha_0, beta_0, theta, y){
alpha_1 = alpha_0 + length(y) / 2
beta_1 = beta_0 + sum((y - theta)^2) / 2
z = rinvgamma(1, alpha_1, scale = beta_1)
param = list(z = z, alpha_1 = alpha_1, beta_1 = beta_1)
return(param)
}
```
6. Check the functions by simulating a large number of data points from a normal distribution using a mean and variance of your own choosing. Store the data points in a vector called y_check. Assume flat priors for the mean and the variance. A vague prior for the inverse gamma has parameters α0=.001 and β0=.001.
Answers
```{r}
set.seed(10)
mean_check = 20
sigma_check = 2
var_check = sigma_check^2
n.draw = 10000
y_check=rnorm(n.draw, mean = mean_check, sd = sigma_check)
var_vec = numeric(n.draw)
mean_vec = numeric(n.draw)
for(i in 1:n.draw) {
var_vec[i] = draw_var(alpha_0 = .001, beta_0 = .001, theta = mean_check, y = y_check)$z
mean_vec[i] = draw_mean(0,10000, sigma_check^2, y_check)$z
}
mean(var_vec)
var_check
mean(mean_vec)
mean_check
```
Writing a sampler
Now execute these steps:
1. Set up a matrix for storing samples from the posterior distribution of the mean. The number of rows should equal the number of chains (3) and number of columns should equal the number of iterations (10,000). Do the same thing for storing samples from the posterior distribution of the variance.
```{r}
n.iter = 10000
n.chains = 3
var.p = matrix(nrow = n.chains, ncol = n.iter)
mean.p = matrix(nrow = n.chains, ncol = n.iter)
```
2. Assign initial values to the first column of each matrix, a different value for each of the chains. These can be virtually any value within the support of the random variable, but it would be fine for this exercise to use values not terribly far away from to those you used to simulate the data, reflecting some prior knowledge. You might try varying these later to show that you will get the same results.
```{r}
var.p[1:3, 1] = c(10,5,.1)
mean.p[1:3, 1] =c (50,20,1)
```
3. Set up nested for loops to iterate from one to the total number of iterations for each of the three chains for each parameter. Use the conjugate functions draw_mean and draw_var to draw a sample from the distribution of the mean using the value of the variance at the current iteration. Then make a draw from the variance using the current value of the mean. Repeat. Assume vague priors for the mean and variance:
```{r}
n.iter=1000
n.chains=3
for(t in 2:n.iter) {
for (j in 1:n.chains) {
var.p[j, t] = draw_var(alpha_0 =.001, beta_0 = .001, theta = mean.p[j ,t], y = y)$z
mean.p[j, t] = draw_mean(mu_0 = 0, sigma.sq_0 = 10000, varsigma.sq = var.p[j, t - 1], y = y)$z
}
}
```
Trace plots and plots of marginal posteriors
1. Discard the first 1000 iterations as burn-in. Plot the value of the mean as a function of iteration number for each chain. This is called a trace plot.
```{r}
burnin = 1000
samplesKept <- (burnin+1):n.iter
knitr::opts_chunk$set(echo = TRUE)
set.seed(10)
library(actuar)
varsigma.sq = 25 #
theta = 100
n = 100
y = rnorm(n, theta, sqrt(varsigma.sq))
# normal likelihood with gamma prior conjugate relationship for variance, assuming mean is known
# alpha_0 is parameter of prior for variance
# beta_0 is parameter of prior for variance
# Note that this uses scale parameterization for inverse gamma
draw_mean = function(mu_0, sigma.sq_0, varsigma.sq, y){
mu_1 =((mu_0 / sigma.sq_0 + sum(y)/varsigma.sq)) / (1/sigma.sq_0 + length(y) / varsigma.sq)
sigma.sq_1 = 1/(1 / sigma.sq_0 + length(y) / varsigma.sq)
z = rnorm(1, mu_1, sqrt(sigma.sq_1))
param = list(z = z, mu_1 = mu_1, sigma.sq_1 = sigma.sq_1)
return(param)
}
# normal likelihood with gamma prior conjugate relationship for variance, assuming mean is known
# alpha_0 is parameter of prior for variance
# beta_0 is parameter of prior for variance
# Note that this uses scale parameterization for inverse gamma
draw_var = function(alpha_0, beta_0, theta, y){
alpha_1 = alpha_0 + length(y) / 2
beta_1 = beta_0 + sum((y - theta)^2) / 2
z = rinvgamma(1, alpha_1, scale = beta_1)
param = list(z = z, alpha_1 = alpha_1, beta_1 = beta_1)
return(param)
}
set.seed(10)
mean_check = 20
sigma_check = 2
var_check = sigma_check^2
n.draw = 10000
y_check=rnorm(n.draw, mean = mean_check, sd = sigma_check)
var_vec = numeric(n.draw)
mean_vec = numeric(n.draw)
for(i in 1:n.draw) {
var_vec[i] = draw_var(alpha_0 = .001, beta_0 = .001, theta = mean_check, y = y_check)$z
mean_vec[i] = draw_mean(0,10000, sigma_check^2, y_check)$z
}
mean(var_vec)
var_check
mean(mean_vec)
mean_check
n.iter = 10000
n.chains = 3
var.p = matrix(nrow = n.chains, ncol = n.iter)
mean.p = matrix(nrow = n.chains, ncol = n.iter)
var.p[1:3, 1] = c(10,5,.1)
mean.p[1:3, 1] =c (50,20,1)
mean.p
mean.p[1,]
knitr::opts_chunk$set(echo = TRUE)
set.seed(10)
library(actuar)
varsigma.sq = 25 #
theta = 100
n = 100
y = rnorm(n, theta, sqrt(varsigma.sq))
# normal likelihood with gamma prior conjugate relationship for variance, assuming mean is known
# alpha_0 is parameter of prior for variance
# beta_0 is parameter of prior for variance
# Note that this uses scale parameterization for inverse gamma
draw_mean = function(mu_0, sigma.sq_0, varsigma.sq, y){
mu_1 =((mu_0 / sigma.sq_0 + sum(y)/varsigma.sq)) / (1/sigma.sq_0 + length(y) / varsigma.sq)
sigma.sq_1 = 1/(1 / sigma.sq_0 + length(y) / varsigma.sq)
z = rnorm(1, mu_1, sqrt(sigma.sq_1))
param = list(z = z, mu_1 = mu_1, sigma.sq_1 = sigma.sq_1)
return(param)
}
# normal likelihood with gamma prior conjugate relationship for variance, assuming mean is known
# alpha_0 is parameter of prior for variance
# beta_0 is parameter of prior for variance
# Note that this uses scale parameterization for inverse gamma
draw_var = function(alpha_0, beta_0, theta, y){
alpha_1 = alpha_0 + length(y) / 2
beta_1 = beta_0 + sum((y - theta)^2) / 2
z = rinvgamma(1, alpha_1, scale = beta_1)
param = list(z = z, alpha_1 = alpha_1, beta_1 = beta_1)
return(param)
}
set.seed(10)
mean_check = 20
sigma_check = 2
var_check = sigma_check^2
n.draw = 10000
y_check=rnorm(n.draw, mean = mean_check, sd = sigma_check)
var_vec = numeric(n.draw)
mean_vec = numeric(n.draw)
for(i in 1:n.draw) {
var_vec[i] = draw_var(alpha_0 = .001, beta_0 = .001, theta = mean_check, y = y_check)$z
mean_vec[i] = draw_mean(0,10000, sigma_check^2, y_check)$z
}
mean(var_vec)
var_check
mean(mean_vec)
mean_check
n.iter = 10000
n.chains = 3
var.p = matrix(nrow = n.chains, ncol = n.iter)
mean.p = matrix(nrow = n.chains, ncol = n.iter)
knitr::opts_chunk$set(echo = TRUE)
set.seed(10)
library(actuar)
varsigma.sq = 25 #
theta = 100
n = 100
y = rnorm(n, theta, sqrt(varsigma.sq))
# normal likelihood with gamma prior conjugate relationship for variance, assuming mean is known
# alpha_0 is parameter of prior for variance
# beta_0 is parameter of prior for variance
# Note that this uses scale parameterization for inverse gamma
draw_mean = function(mu_0, sigma.sq_0, varsigma.sq, y){
mu_1 =((mu_0 / sigma.sq_0 + sum(y)/varsigma.sq)) / (1/sigma.sq_0 + length(y) / varsigma.sq)
sigma.sq_1 = 1/(1 / sigma.sq_0 + length(y) / varsigma.sq)
z = rnorm(1, mu_1, sqrt(sigma.sq_1))
param = list(z = z, mu_1 = mu_1, sigma.sq_1 = sigma.sq_1)
return(param)
}
# normal likelihood with gamma prior conjugate relationship for variance, assuming mean is known
# alpha_0 is parameter of prior for variance
# beta_0 is parameter of prior for variance
# Note that this uses scale parameterization for inverse gamma
draw_var = function(alpha_0, beta_0, theta, y){
alpha_1 = alpha_0 + length(y) / 2
beta_1 = beta_0 + sum((y - theta)^2) / 2
z = rinvgamma(1, alpha_1, scale = beta_1)
param = list(z = z, alpha_1 = alpha_1, beta_1 = beta_1)
return(param)
}
set.seed(10)
mean_check = 20
sigma_check = 2
var_check = sigma_check^2
n.draw = 10000
y_check=rnorm(n.draw, mean = mean_check, sd = sigma_check)
var_vec = numeric(n.draw)
mean_vec = numeric(n.draw)
for(i in 1:n.draw) {
var_vec[i] = draw_var(alpha_0 = .001, beta_0 = .001, theta = mean_check, y = y_check)$z
mean_vec[i] = draw_mean(0,10000, sigma_check^2, y_check)$z
}
mean(var_vec)
var_check
mean(mean_vec)
mean_check
n.iter = 10000
n.chains = 3
var.p = matrix(nrow = n.chains, ncol = n.iter)
mean.p = matrix(nrow = n.chains, ncol = n.iter)
draw_mean()
draw_var
n.iter=1000
n.chains=3
j=1
t=2
draw_var(alpha_0 =.001, beta_0 = .001, theta = mean.p[j ,t], y = y)$z
draw_mean(mu_0 = 0, sigma.sq_0 = 10000, varsigma.sq = var.p[j, t - 1], y = y)$z
mu_1
set.seed(10)
library(actuar)
varsigma.sq = 25 #
theta = 100
n = 100
y = rnorm(n, theta, sqrt(varsigma.sq))
draw_mean = function(mu_0, sigma.sq_0, varsigma.sq, y){
mu_1 =((mu_0 / sigma.sq_0 + sum(y)/varsigma.sq)) / (1/sigma.sq_0 + length(y) / varsigma.sq)
sigma.sq_1 = 1/(1 / sigma.sq_0 + length(y) / varsigma.sq)
z = rnorm(1, mu_1, sqrt(sigma.sq_1))
param = list(z = z, mu_1 = mu_1, sigma.sq_1 = sigma.sq_1)
return(param)
}
mean_check = 20
sigma_check = 2
var_check = sigma_check^2
n.draw = 10000
y_check=rnorm(n.draw, mean = mean_check, sd = sigma_check)
var_vec = numeric(n.draw)
mean_vec = numeric(n.draw)
for(i in 1:n.draw) {
var_vec[i] = draw_var(alpha_0 = .001, beta_0 = .001, theta = mean_check, y = y_check)$z
mean_vec[i] = draw_mean(0,10000, sigma_check^2, y_check)$z
}
mean(var_vec)
var_check
mean(mean_vec)
mean_check
n.iter = 10000
n.chains = 3
var.p = matrix(nrow = n.chains, ncol = n.iter)
mean.p = matrix(nrow = n.chains, ncol = n.iter)
var.p[1:3, 1] = c(10,5,.1)
mean.p[1:3, 1] =c (50,20,1)
n.iter=1000
n.chains=3
for(t in 2:n.iter) {
for (j in 1:n.chains) {
var.p[j, t] = draw_var(alpha_0 =.001, beta_0 = .001, theta = mean.p[j ,t], y = y)$z
mean.p[j, t] = draw_mean(mu_0 = 0, sigma.sq_0 = 10000, varsigma.sq = var.p[j, t - 1], y = y)$z
}
}
for(t in 2:n.iter) {
for (j in 1:n.chains) {
var.p[j, t] = draw_var(alpha_0 =.001, beta_0 = .001, theta = mean.p[j ,t], y = y)$z
mean.p[j, t] = draw_mean(mu_0 = 0, sigma.sq_0 = 10000, varsigma.sq = var.p[j, t - 1], y = y)$z
}
}
mean_check = 32
sigma_check = 3.2
var_check = sigma_check^2
n.draw = 10000
y_check=rnorm(n.draw, mean = mean_check, sd = sigma_check)
var_vec = numeric(n.draw)
mean_vec = numeric(n.draw)
for(i in 1:n.draw) {
var_vec[i] = draw_var(alpha_0 = .001, beta_0 = .001, theta = mean_check, y = y_check)$z
mean_vec[i] = draw_mean(0,10000, sigma_check^2, y_check)$z
}
mean(var_vec)
var_check
mean(mean_vec)
mean_check
n.iter = 10000
n.chains = 3
var.p = matrix(nrow = n.chains, ncol = n.iter)
mean.p = matrix(nrow = n.chains, ncol = n.iter)
var.p[1:3, 1] = c(10,5,.1)
mean.p[1:3, 1] =c (50,20,1)
for(t in 2:n.iter) {
for (j in 1:n.chains) {
var.p[j, t] = draw_var(alpha_0 =.001, beta_0 = .001, theta = mean.p[j ,t], y = y)$z
mean.p[j, t] = draw_mean(mu_0 = 0, sigma.sq_0 = 10000, varsigma.sq = var.p[j, t - 1], y = y)$z
}
}
input<-c(3,10,4,12,55)
output<-numeric(length(input))
f(i in 1:length(input)){
output[i]<-sum(input[1:i])
}
length(input)
numeric(length(input))
output<-numeric(length(input))
input<-c(3,10,4,12,55)
f(i in 1:length(input)){
output[i]<-sum(input[1:i])
}
input<-c(3,10,4,12,55)
output<-numeric(length(input))
f(i in l:length(input)){
output[i]<-sum(input[1:i])
}
sum(input[1:i])
input<-c(3,10,4,12,55)
output<-numeric(length(input))
for(i in 1:length(input)){
output[i]<-sum(input[1:i])
}
output
a<-rep(5,4)
b<-rep(10,4)
a+b
a<-rep(5,4)
b<-rep(10,4)
a+b
c=10
a+c
getwd()
file<-read.csv("toolik_solarrad")
getwd()
states<-read.csv("stateLatLong.csv")
View(states)
install.packages("ggplot2")
install.packages("cowplot")
install.packages("reshape2")
library(ggplot2)
library(cowplot)
library(reshape2)
mpg=read.table("mpg.txt",sep='\t',header=T,stringsAsFactors=F)
View(mpg)
View(mpg)
head(mpg)
a=ggplot(data=mpg,mapping=aes(x=displ,y=cty))
a+geom_line(aes(color=drv))+
stat_smooth(method="loess",color="black") #add linear model
facet_grid(.~year) #separate by year; share everything but year
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
ggplot(data=mpg,mapping=aes(x=cty,y=hwy))
a=ggplot(data=mpg,mapping=aes(x=displ,y=cty))
a+geom_line(aes(color=drv))+
stat_smooth(method="loess",color="black") #add linear model
facet_grid(.~year) #separate by year; share everything but year
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
ggplot(mpg,mapping=aes(cty,hwy))
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
m<-ggplot(mpg,aes(cty,hwy))
View(m)
View(mpg)
library(ggplot2)
library(cowplot)
library(reshape2)
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
m<-geom_pint(cty,hwy)
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
m<-geom_point(cty,hwy)
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
m<-geom_point('cty','hwy')
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
m<-geom_point('cty','hwy',aes)
head(mpg)
a=ggplot(data=mpg,mapping=aes(x=displ,y=cty))
a+geom_line(aes(color=drv))+
stat_smooth(method="loess",color="black") #add linear model
facet_grid(.~year) #separate by year; share everything but year
#multi-panel plots that are unrelated
b=a+geom_point(color="blue",size=3)+
xlab("Displacement")+ylab("MPG-City")+
theme_bw()
c=ggplot(mpg,aes(y=cty,x=displ))+
stat_summary(geom="bar",fun.y="mean")
b
c
plot_grid(a,b,c,ncol=3) #ncol puts plots next to eachother
a=ggplot(data=mpg,mapping=aes(x=hwy,y=cty))
a=ggplot(data=mpg,mapping=aes(x=hwy,y=cty))
a+geom_line(aes(color=drv))+
stat_smooth(method="loess",color="black") #add linear model
facet_grid(.~year) #separate by year; share everything but year
b=a+geom_point(color="blue",size=3)+
xlab("Displacement")+ylab("MPG-City")+
theme_bw()
c=ggplot(mpg,aes(y=cty,x=displ))+
stat_summary(geom="bar",fun.y="mean")
b
c
plot_grid(a,b,c,ncol=3) #ncol puts plots next to eachother
c=ggplot(mpg,aes(y=cty,x=displ))+
stat_summary(geom="bar",fun.y="mean")
plot_grid(a,b,c,ncol=3)
#Challenge 2: "Density plot" of engine displacement. Save figure to computer using ggsave().
a+geom_density()
#Challenge 2: "Density plot" of engine displacement. Save figure to computer using ggsave().
a+geom_density(x,y)
#Challenge 2: "Density plot" of engine displacement. Save figure to computer using ggsave().
a+geom_density(displ)
#Challenge 2: "Density plot" of engine displacement. Save figure to computer using ggsave().
a+geom_density('displ')
#Challenge 2: "Density plot" of engine displacement. Save figure to computer using ggsave().
a+geom_density('displ',aes(color='model'))
#Challenge 2: "Density plot" of engine displacement. Save figure to computer using ggsave().
a+geom_density('displ',aes(x=displ,y=model))
#Challenge 1: Scatter plot of mpg city vs mpg highway. Color code pts by 'drv' (four-wheel,front-wheel,rear-wheel). Add linear trendline to plot.
a=ggplot(data=mpg,mapping=aes(x=hwy,y=cty))
a+geom_line(aes(color=drv))+
stat_smooth(method="loess",color="black") #add linear model
facet_grid(.~year) #separate by year; share everything but year
rm(list=ls())
#C1 Answer:
a=ggplot(data=mpg,aes(x=cty,y=hwy))+geom_point()
#C1 Answer:
a=ggplot(data=mpg,aes(x=cty,y=hwy))+geom_point()
#C1 Answer:
d=ggplot(data=mpg,aes(x=cty,y=hwy))+geom_point()
a
a #ggplot only plots when you call it by the variablee; run only a
a #ggplot only plots when you call it by the variablee; run only a
#C2 Answer:
b=ggplot(mpg,aes(x=displ))+geom_density()
b
c
c=ggplot(mpg,aes(x=cyl,y=displ))+
stat_summary(geom="bar",fun.y="mean")+
stat_summary(geom="errorbar",fun.data="mean_se",width=0.3)
c
mpg2=mpg
mpg2$cyl=as.character(mpg2$cyl)
c=ggplot(mpg,aes(x=cyl,y=displ))+
stat_summary(geom="bar",fun.y="mean")+
stat_summary(geom="errorbar",fun.data="mean_se",width=0.3)
c
mpg2=mpg
mpg2$cyl=as.character(mpg2$cyl)
c=ggplot(mpg,aes(x=cyl,y=displ))+
rm(list=ls())
setwd("~/Desktop/ICB2019_Exercise08")
df <- read.table("UWvMSU_1-22-13.txt", header = T)
rm(list=ls())
setwd("~/ICB2019_Exercise08")
df <- read.table("UWvMSU_1-22-13.txt", header = T)
rm(list=ls())
setwd("ICB2019_Exercise08")
df <- read.table("UWvMSU_1-22-13.txt", header = T)
View(df)
states<-read.csv("stateLatLong.csv")
install.packages("ggmap")
install.packages("maps")
install.packages("mapdata")
install.packages("usmap")
library(ggmap)
library(maps)
library(mapdata)
library(usmap)
rm(list=ls())
("stateLatLong.csv")
statell<-read.csv("stateLatLong.csv")
getwd()
statell<-read.csv("stateLatLong.csv")
statell<-read.csv("stateLatLong.csv")
install.packages("ggmap")
install.packages("ggmap")
statell<-read.csv("stateLatLong.csv")
getwd()
setwd("C:/Users/Owner/Desktop/")
statell<-read.csv("stateLatLong.csv")
View(statell)
states<-map_data("state")
View(states)
ggplot(data=states)+
geom_polygon(aes(x=long,y=lat,group=group),color="black")+coord_quickmap()
states<-map_data("state")
ggplot(data=states)+
geom_polygon(aes(x=long,y=lat,group=group),color="black")+coord_quickmap()
ggplot(data=texas)+ #for all states
geom_polygon(aes(x=long,y=lat,group=group),color="black")+coord_quickmap()
rm(list=ls())
library(ggmap)
library(maps)
library(mapdata)
library(usmap)
states<-map_data("state")
ggplot(data=states)+ #for all states
geom_polygon(aes(x=long,y=lat,group=group),color="black")+coord_quickmap()
#Alexa Salinas and Camille Mosley - Exercise 08
#1.
rm(list=ls())
setwd("ICB2019_Exercise08") #when working dir is set to Desktop
df <- read.table("UWvMSU_1-22-13.txt", header = T)
View(df)
getwd()
